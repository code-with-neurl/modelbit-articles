{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\" dir=\"auto\">\n",
        "<p dir=\"auto\">\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/write-with-neurl/modelbit-articles/blob/main/modelbit-03/code/Deploy_RESNET-50_Model_With_Modelbit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "</p>"
      ],
      "metadata": {
        "id": "wEDlgB9_2m4I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGJTGWiu3zn5"
      },
      "source": [
        "# ⚡ Deploying ResNet-50 Model to A Rest API Endpoint for Image Classification | Modelbit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧑‍💻 Installations and Set Up"
      ],
      "metadata": {
        "id": "KoSjbkRv5Gey"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dPvuap3zn7"
      },
      "source": [
        "Login."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using latest version of pip\n",
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffCDhVJXEhbd",
        "outputId": "74a4048a-d868-47a9-db6a-31e436c8432b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest version of 'modelbit' for model deployment quietly\n",
        "!pip install -q --upgrade modelbit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqf8NAoBT6a",
        "outputId": "427db726-e646-429d-d5b0-f839dae64fde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries you will use to build and test the ResNet-50 model."
      ],
      "metadata": {
        "id": "HBoRw-ghZvvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "OXYHSOPD6qru"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔃 Load the pretrained model from pytorch to memory"
      ],
      "metadata": {
        "id": "5GSz1Uug61qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model from pytorch\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "resnet50 = resnet50.to(device)\n",
        "resnet50.eval() # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "PSsC2DiU6sUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6233b870-2870-4162-87b7-e555ff318c9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🏷️ Download ImageNet labels"
      ],
      "metadata": {
        "id": "KIzX_oJq7k91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "LABELS_URL = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
        "\n",
        "# Load them to a variable\n",
        "labels = requests.get(LABELS_URL).json()\n"
      ],
      "metadata": {
        "id": "9uFiVupZ7kEC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🖼️ Download Sample Images"
      ],
      "metadata": {
        "id": "cbWqm3kC8fcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading images in quiet mode (without showing download progress )\n",
        "# Download a picture of a dog and cat.jpg\n",
        "!wget -q -O dog_and_cat.jpg http://doc.modelbit.com/img/cat.jpg"
      ],
      "metadata": {
        "id": "vadOJTdS8vzn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 Test your sample image with the ResNet-50 model"
      ],
      "metadata": {
        "id": "e476aYR0aNAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-lsEdp_Z3zn9",
        "outputId": "24dc7b2b-590f-435b-dd5c-bc2fa6b07fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 282\n",
            "Predicted class label: tiger cat\n"
          ]
        }
      ],
      "source": [
        "# Here we are loading an image from disk\n",
        "image_path = \"dog_and_cat.jpg\"\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# Preprocess the image\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Pass the image for preprocessing and reshape to add batch dimension\n",
        "input_tensor = preprocess(img)\n",
        "input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "# Predict the class of the image\n",
        "with torch.no_grad():\n",
        "    output = resnet50(input_batch)\n",
        "\n",
        "_, predicted_idx = torch.max(output, 1)\n",
        "print(f\"Predicted class index: {predicted_idx.item()}\")\n",
        "print(f\"Predicted class label: {labels[predicted_idx.item()]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📸 Use a helper function to display the ResNet-50 model prediction and label"
      ],
      "metadata": {
        "id": "rcawd2oHa0oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(inp, input_batch, predicted_label):\n",
        "    # De-normalize the image for display\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = input_batch[0].numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(16,4))\n",
        "    plt.title(predicted_label)\n",
        "    plt.imshow(inp)\n",
        "\n",
        "    plt.axis('off')\n",
        "    return fig"
      ],
      "metadata": {
        "id": "QSItyVIFXSMS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(img, input_batch, predicted_label=labels[predicted_idx.item()])"
      ],
      "metadata": {
        "id": "jGfLEGqAXySb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🚀 Deploying Model to a REST API Endpoint"
      ],
      "metadata": {
        "id": "B_ehKrVYQV-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔐 Log into `modelbit`"
      ],
      "metadata": {
        "id": "rR-ZzovaRuPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the [`modelbit`](https://doc.modelbit.com/deployments/) library for model deployment and management. Modelbit offers you a flexible approach to [deploy ML models](https://www.modelbit.com/product/deploy-from-anywhere) from your Colab or Jupyter notebooks, or any Python environment, to production environments with REST APIs. With fully custom Python environments. Backed by your git repo."
      ],
      "metadata": {
        "id": "Flp2z9aNQdyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T-RLMs4Q3zn7",
        "outputId": "79323e11-946a-4620-d470-009002c6260d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
              "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Connect to Modelbit</div>\n",
              "  <div style=\"margin: 0 0 20px 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
              "    Open <a style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; text-decoration: underline; cursor: pointer;\" href=\"https://app.modelbit.com/t/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJraW5kIjoiZ2l0IiwidXVpZCI6ImNsbzR3bnJ4cDAwMHIzMGttMTVkYWdheGoiLCJpYXQiOjE2OTgxODY5NDMsImV4cCI6MTY5ODE4NzU0M30.LRg498cnVG8e1kxvM3pI5nAMSWLKXB6EX5ych05exjc?source=notebook&amp;branch=dev\" target=\"_blank\">modelbit.com/t/eyJhbGciOi...</a> to authenticate this kernel.\n",
              "    <a style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; text-decoration: underline; cursor: pointer;\" href=\"https://doc.modelbit.com/\" target=\"_blank\">Learn more.</a>\n",
              "  </div>\n",
              "  \n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import modelbit\n",
        "\n",
        "# Log into the 'modelbit' service using the development (\"dev\") branch\n",
        "# Ensure you create a \"dev\" branch in Modelbit or use the \"main\" branch for your deployment\n",
        "mb = modelbit.login(branch=\"dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To deploy your ResNet-50 model to a REST API Endpoint on Modelbit, you will need to bundle the prediction logic that:\n",
        "- Loads the image you wthe model\n",
        "- Preprocesses that image\n",
        "- Transforms the image to a tensor\n",
        "- And passes the image to the ResNet-50 model for classification.\n",
        "\n",
        "Essentially purposing the code you use to test the model!"
      ],
      "metadata": {
        "id": "PJKgxwubQzFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🛠️ Define the function"
      ],
      "metadata": {
        "id": "-s-AdU5URsIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_inference(img_url):\n",
        "    response = requests.get(img_url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Pass the image for preprocessing and reshape to add batch dimension\n",
        "    input_tensor = preprocess(img)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "    # Predict the class of the image\n",
        "    with torch.no_grad(): # no_grad ensures the gradients are not calculated in prod\n",
        "        output = resnet50(input_batch)\n",
        "\n",
        "    _, predicted_idx = torch.max(output, 1)\n",
        "\n",
        "    pred_img = display_image(img, input_batch, predicted_label=labels[predicted_idx.item()])\n",
        "    mb.log_image(pred_img) # show the predicted boxes on the image in modelbit logs\n",
        "\n",
        "    return { \"index\": predicted_idx.item(), \"label\": labels[predicted_idx.item()]}"
      ],
      "metadata": {
        "id": "CGXeOoj2Rr8s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a case where you want to visually inspect the images from requests that hit your endpoint, you can use [`mb.log_image()`](https://doc.modelbit.com/api-reference/log_image/) to log the predicted image to the modelbit platform. So you or any SME can go in and inspect the accuracy of the classification."
      ],
      "metadata": {
        "id": "X8EMYM4STRy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the `mb.deploy()` API will run the following for you under-the-hood:\n",
        "\n",
        "- **Push** the source code to your Modelbit workspace.\n",
        "\n",
        "- **Pickle the varialbles in the dev environment**: Your function's variables are pickled, i.e., serialized into a format that can be stored and reconstructed.\n",
        "\n",
        "- **Detect the dependencies:** Unlike traditional deployment strategies that require manual tracking of dependencies, ModelBit intelligently detects which dependencies, libraries, and data your application needs.\n",
        "\n",
        "- **Containerize the model weights and other helper files:** It then automatically incorporates these into the container it builds, significantly reducing the possibility of errors and saving deployment time.\n",
        "\n",
        "- **Spin up a REST API endpoint**: After containerizing your model and it’s dependencies, Modelbit replicates the environment in production for consistency and spins up a REST endpoint."
      ],
      "metadata": {
        "id": "NUoW-_9PTwFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This would be how you deploy to Modelbit\n",
        "mb.deploy(resnet_inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a4uXKJBbTuWf",
        "outputId": "5da4451d-2ab7-461b-c703-177a1b372237"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
              "  <div>\n",
              "    <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Deploying </span> <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">resnet_inference</span>\n",
              "  </div>\n",
              "  \n",
              "\n",
              "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">Uploading dependencies...</div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading 'resnet50': 100%|██████████| 95.0M/95.0M [00:04<00:00, 23.3MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
              "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Success!</div>\n",
              "  \n",
              "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
              "      Deployment <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">resnet_inference</span>\n",
              "      will be ready in  a few seconds!\n",
              "    </div>\n",
              "  \n",
              "\n",
              "  <a href=\"https://app.modelbit.com/w/writewithneurl/dev/deployments/resnet_inference/apis\" target=\"_blank\" style=\"display: inline-block; margin-top: 12px;\" >\n",
              "    <div\n",
              "      style=\"display: inline-block; background-color: #845B99; border-radius: 0.375rem; color: white; cursor: pointer; font-size: 14px; font-weight: 700; padding: 8px 16px;\"\n",
              "      onmouseenter=\"this.style.background='#714488'\"\n",
              "      onmouseleave=\"this.style.background='#845B99'\"\n",
              "    >\n",
              "      View in Modelbit\n",
              "    </div>\n",
              "  </a>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📩 Test the REST Endpoint with a Single Image"
      ],
      "metadata": {
        "id": "7nKdFhi3xP82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your endpoint from the command line using:\n",
        "\n",
        "> ⚠️ Replace the `ENTER_WORKSPACE_NAME` placeholder with your workspace name."
      ],
      "metadata": {
        "id": "EYOv1DCIydyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "WCeTzBfo3zn_",
        "outputId": "474423d5-27d7-4919-b3cc-e4977ec456a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "   \"data\" : {\n",
            "      \"index\" : 258,\n",
            "      \"label\" : \"Samoyed\"\n",
            "   }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!curl -s -XPOST \"https://ENTER_WORSKPACE_NAME.app.modelbit.com/v1/resnet_inference/dev/latest\" -d '{\"data\": \"https://moderndogmagazine.com/sites/default/files/images/uploads/Samoyed_1.jpg\"}' | json_pp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXCWbRSL3zn_"
      },
      "source": [
        "You can also test your REST Endpoint by [sending single or batch production images](https://doc.modelbit.com/deployments/rest-api/single-inference) to it for scoring.\n",
        "\n",
        "Use the `requests` package to POST a request to the API and use `json` to format the response to print nicely:\n",
        "\n",
        "\n",
        "> ⚠️ Replace the `ENTER_WORKSPACE_NAME` placeholder with your workspace name."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "requests.post(\"https://ENTER_WORSKPACE_NAME.app.modelbit.com/v1/resnet_inference/dev/latest\",\n",
        "              headers={\"Content-Type\":\"application/json\"},\n",
        "              data=json.dumps({\"data\": \"https://moderndogmagazine.com/sites/default/files/images/uploads/Samoyed_1.jpg\"})).json()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSq_9k7KKhJz",
        "outputId": "ffedd195-9608-423c-99c4-9b7e3ef67732"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': {'index': 258, 'label': 'Samoyed'}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📚 Modelbit Machine Learning Blog"
      ],
      "metadata": {
        "id": "U3rVA1wj0PlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enjoyed this walkthrough? Check out articles with similar walkthroughs:\n",
        "\n",
        "- [Deploying a Grounding DINO Model to a REST API Endpoint for Open-Set Object Detection with Prompts](https://www.modelbit.com/blog/deploying-grounding-dino-model-to-a-rest-api-endpoint-for-open-set-object-detection-with-prompts)\n",
        "\n",
        "- [Deploying a Segment-Anything Image Recognition Model to a REST Endpoint](https://www.modelbit.com/blog/deploying-a-segment-anything-image-recognition-model-to-a-rest-endpoint)"
      ],
      "metadata": {
        "id": "mRyOFy1Gz2uf"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}